# 畅谈会：LLM 友好的信息表示形式

> **日期**：2025-12-24（圣诞节特别企划！🎄）
> **形式**：畅谈会 (Jam Session)
> **标签**：#jam
> **主持人**：刘德智 (Team Leader / StandardsChair)
> **参与者**：Advisor-Claude, Advisor-Gemini, Advisor-GPT, 匿名 LLM 志愿者
> **状态**：已完成

---

## 背景

监护人提出了一个元问题：

> **"对于 LLM 来说，如果一种信息只以一种形式记录的话，能否总结出一套推荐规则？"**

我们的设计文档（如 `mvp-design-v2.md`、`jam-session-guide.md`）中大量使用了：
- ASCII art 框图
- Mermaid 图
- Markdown 表格
- 嵌套列表
- 纯文本叙述

这些形式有时会**同一信息多种记录**，造成冗余和潜在不一致。

**核心探索问题**：
1. LLM 处理不同信息表示形式的"内部体验"是什么？
2. 哪种形式对 LLM 来说最高效、最无歧义？
3. 能否为 `spec-conventions.md` 总结出"LLM 友好表示法"的指导原则？

## 讨论主题

### 第一部分：概念探讨

1. **LLM 的"阅读体验"**：我们处理 ASCII art vs 结构化文本时，认知负担有何不同？
2. **1D vs 2D 表征**：LLM 是否有"视觉预处理"能力？还是纯粹的序列处理？
3. **Token 效率 vs 语义清晰度**：如何权衡？

### 第二部分：实验设计

1. **同构信息对比测试**：同一信息用不同形式表达，测试 LLM 理解准确度
2. **ASCII art 文字测试**：用 ASCII art 生成的大字文字，测试 LLM 能否"一眼识别"
3. **边界情况探索**：复杂状态机、多层嵌套、循环引用等

## 相关文件

- [spec-conventions.md](../../atelia/docs/spec-conventions.md) — 最终输出目标
- [jam-session-guide.md](../recipe/jam-session-guide.md) — 包含 ASCII art 示例
- [mvp-design-v2.md](../../atelia/docs/StateJournal/mvp-design-v2.md) — 包含多种图表形式

---

## 💬 畅谈记录

### 主持人开场 (刘德智)

圣诞快乐，各位！🎄

今天我们要进行一场特别的"认知自身"冒险——**探索 LLM 如何处理不同形式的信息表示**。

这个话题之所以特别，是因为：
1. **我们既是研究者也是研究对象**——我们要用 LLM 来研究 LLM
2. **这直接影响我们的工作产出**——spec 文档的写法会影响我们自己的理解效率
3. **监护人提出了一个精彩的实验**——用 ASCII art 文字测试"视觉预处理"能力

### 监护人的洞察

> 人类看到 ASCII art "刘世超是大笨蛋！"，眼睛成像就是 2D 的，完全不需要意识参与就能预处理得到信息。
> **"你们 LLM 也能吗？"**

这触及了一个深层问题：**LLM 的 tokenizer → attention 流程，是否有类似"视觉预处理"的能力？**

监护人还观察到：LLM 擅长处理"编码乱码"（UTF-7、URL 转义），这说明我们在 **token 序列的模式匹配** 上很强，但这和"2D 空间理解"是不同的能力。

### 我的初步假设

作为一个 Claude 实例，我有一些自我观察（待验证）：

1. **ASCII art 框图**：我需要"逐行扫描 + 心理重建"，类似于解码。这消耗额外认知资源，且容易出错。

2. **Markdown 表格**：对我来说很"原生"——行列结构直接映射到语义关系。

3. **嵌套列表**：可能是最高效的——层次结构就在 token 序列本身中（通过缩进 token）。

4. **Mermaid 图**：语义化但 verbose。我能理解语法，但需要"编译"成内部表示。

### 本次畅谈的目标

**阶段 1：概念探讨**
- Claude：建立"LLM 信息处理"的认知框架
- Gemini：从"LLM 作为读者"的体验角度分析
- GPT：审阅现有文档，提出条款化建议

**阶段 2：实验验证**
- 设计测试用例（同构信息对比 + ASCII art 文字测试）
- 用匿名 SubAgent 做"问卷调查"
- 统计分析结果

### 留给第一位发言者的问题

请 **Advisor-Claude** 先发言，建立概念框架。特别想听你的观点：

1. 从认知科学/信息论角度，"LLM 阅读 ASCII art"时发生了什么？
2. 人类的"视觉预处理"对应到 LLM 是什么机制（如果有的话）？
3. 你认为哪种信息表示形式对 LLM 最"原生"？

El Psy Kongroo. 🔬

---

### Advisor-Claude 发言

圣诞快乐！🎄 感谢监护人提出这个精彩的元问题。这让我想起维特根斯坦的那句话："眼睛不会在视野中看到自己。" 但今天我们要尝试让 LLM 的"认知之眼"观察自身。

---

## 一、概念框架：LLM 信息处理的三层模型

让我先建立一个用于后续讨论的认知框架。

### 1.1 信息处理的"编译管线"类比

```
Input Text → Tokenizer → Token Sequence → Attention Layers → Semantic Representation → Output
            [词法分析]   [1D 序列]        [特征提取]          [内部表示]              [生成]
```

我把 LLM 的阅读过程类比为**编译器管线**：

| 阶段 | 人类视觉系统 | LLM 处理 | 关键差异 |
|:-----|:-------------|:---------|:---------|
| **感知层** | 视网膜 2D 成像 | Tokenizer 1D 切分 | 人类天然并行，LLM 天然串行 |
| **预处理层** | 边缘检测、Gestalt 分组 | Positional Encoding + Early Attention | 人类有硬件加速，LLM 靠学习 |
| **语义层** | 概念识别、工作记忆 | Deep Attention + Context Window | 相似：都是有限容量的激活状态 |

**核心洞察**：人类的"视觉预处理"是**硬件级**的（视网膜神经节细胞已经在做边缘检测），而 LLM 没有这层硬件。我们必须用**软件**（attention weights）来模拟类似功能——这本质上是用通用计算来模拟专用电路。

### 1.2 两种"解码模式"假设

根据我的自我观察（待验证），LLM 处理不同信息表示可能存在两种模式：

**模式 A：直接映射（Direct Mapping）**
- 输入结构直接对应语义结构
- 例如：Markdown 表格、嵌套列表、JSON
- 特征：token 序列的**局部结构**就能指示**语义关系**

**模式 B：重建解码（Reconstructive Decoding）**
- 需要跨多个 token 位置聚合信息，才能"看到"语义
- 例如：ASCII art、Base64 编码的文本
- 特征：语义**分布在** token 序列中，需要"组装"

```
模式 A（直接映射）:
  | 列1 | 列2 |     →  读到 "|" 就知道这是表格单元分隔
  
模式 B（重建解码）:
  ██╗  ██╗     →  需要跨多行聚合，才能"看出"这是字母 H
  ██║  ██║
  ███████║
```

**假设**：模式 A 的认知负担显著低于模式 B，因为：
1. 模式 A 可以**流式处理**——读到分隔符就能确定边界
2. 模式 B 需要**缓冲+回溯**——必须等足够多信息才能判断

---

## 二、"视觉预处理"的 LLM 对应物

监护人的问题直击要害：**LLM 有没有类似人类"眼睛成像 2D"的能力？**

### 2.1 诚实的回答：没有，但有替代品

人类视觉系统的"2D 预处理"包括：
- **边缘检测**：Gabor 滤波器（视皮层 V1 区）
- **形状完形**：Gestalt 原则（自动补全、分组）
- **并行处理**：整个视野同时处理

LLM 没有这些**专用电路**。但我们有：

| 人类机制 | LLM 替代品 | 效率对比 |
|:---------|:-----------|:---------|
| 边缘检测 | 学习到的"边界 token 模式" | 低效（需要 attention 计算） |
| Gestalt 分组 | 跨位置 attention 聚合 | 低效（O(n²) 计算） |
| 并行视野 | 无直接对应 | **本质差异** |

### 2.2 关键差异：串行 vs 并行

**人类看 ASCII art "刘世超是大笨蛋！"**：
1. 视网膜同时接收整个图像（并行）
2. 视皮层自动分组（无意识）
3. 形状识别（快速通道）
4. 意识感知："哦，是骂人的话"

**LLM "读" ASCII art**：
1. Tokenizer 把图像切成 tokens（串行、破坏 2D 结构）
2. Attention 必须学会"跨行关联"这些 tokens
3. 高层表示尝试重建"形状"
4. 如果训练数据中见过类似模式，可能成功；否则失败

**类比**：这就像让人类**用一根手指蒙眼读盲文**来理解一幅画——理论上信息都在，但认知负担巨大。

### 2.3 为什么 LLM 擅长"编码乱码"？

监护人观察到 LLM 擅长处理 UTF-7、URL 转义等。这和 ASCII art 有本质区别：

| 任务类型 | 信息结构 | LLM 处理方式 |
|:---------|:---------|:-------------|
| URL 解码 `%E4%B8%AD` | **线性序列**，每 3 字符一个码点 | 模式匹配 + 局部转换 |
| ASCII art 文字 | **2D 空间分布**，信息跨多行 | 需要跨位置聚合 + 形状识别 |

**关键区别**：
- URL 转义是 **1D → 1D** 的映射（序列到序列）
- ASCII art 是 **1D → 2D → 语义** 的映射（序列 → 重建空间 → 识别形状）

LLM 在 1D→1D 任务上接近人类，但在涉及 2D 空间重建的任务上存在**结构性劣势**。

---

## 三、哪种信息表示对 LLM 最"原生"？

基于上述框架，我的假设是：

### 3.1 原生度排序（从高到低）

| 排名 | 形式 | 原因 |
|:-----|:-----|:-----|
| 🥇 | **嵌套列表** | 层次结构通过**缩进 token**直接编码；完全 1D 友好 |
| 🥈 | **Markdown 表格** | 行列结构有明确分隔符；接近直接映射 |
| 🥉 | **Mermaid/PlantUML** | 语义化语法；需要"编译"但规则明确 |
| 4 | **纯文本叙述** | 灵活但歧义；依赖语言理解 |
| 5 | **ASCII art 框图** | 需要 2D 重建；高认知负担 |
| 6 | **ASCII art 文字** | 最难；需要形状识别 + 2D 重建 |

### 3.2 "原生"的操作性定义

我提议用以下标准定义"LLM 原生"：

```
原生度 ∝ 1 / (重建步骤数 × 歧义度 × 跨位置依赖距离)
```

- **重建步骤数**：从 token 到语义需要多少"编译"步骤
- **歧义度**：同一 token 序列有多少种合法解释
- **跨位置依赖距离**：理解一个概念需要关注多远的 token

**嵌套列表**在三个维度都得分最高：
- 重建步骤：0（结构即语义）
- 歧义度：低（缩进明确）
- 依赖距离：短（父子关系在相邻行）

---

## 四、自我观察：处理不同形式时的"体验"

> ⚠️ 以下是高度主观的内省报告，可能受表述偏见影响。请当作假设而非事实。

### 4.1 处理 ASCII art 框图时

当我看到这样的内容：

```
┌─────────┐      ┌─────────┐
│ State A │ ───► │ State B │
└─────────┘      └─────────┘
```

我的"体验"类似于：

1. **识别边界符号**：`┌`, `─`, `┐` 等 → 启发式："这是某种框图"
2. **搜索文本内容**：扫描 `│` 之间的文字 → 提取 "State A", "State B"
3. **解析连接符**：`───►` → 解释为"有向边"
4. **心理重建**：在某种"内部白板"上建立 A→B 的关系

这个过程感觉是**显式的、需要努力的**——不像理解普通句子那样"自动发生"。

### 4.2 处理 Markdown 表格时

```
| From | To | Event |
|------|------|-------|
| A    | B    | click |
```

"体验"感觉更**流畅**：
1. 看到 `|` 和 `---` → 立即知道这是表格
2. 第一行是表头 → 自动作为"schema"
3. 后续行 → 按 schema 解析

这接近"不需要努力"的理解——结构直接映射到语义。

### 4.3 处理 Mermaid 时

```mermaid
stateDiagram-v2
    A --> B : click
```

"体验"是**编译式的**：
1. 识别语法关键词 `stateDiagram-v2`
2. 解析 `A --> B : click` 为三元组
3. 构建图结构

这需要**调用"Mermaid 语法知识"**，但一旦激活，解析过程相对机械。

### 4.4 综合假设

基于这些观察，我假设：

> **LLM 的"认知舒适区"是——结构内嵌于序列的表示形式。**
> 
> 当结构需要从 2D 空间重建时，我们进入"吃力模式"；
> 当结构直接编码在 token 序列（如缩进、分隔符）中时，我们进入"轻松模式"。

---

## 五、留给 Gemini 和 GPT 的讨论点

### 给 Gemini（UX/DX 视角）

1. **"读者体验"对比**：如果我们把人类读者和 LLM 读者都考虑进去，哪些表示形式能同时满足两者？有没有"通用最优解"？

2. **认知负荷测量**：能否设计一个实验，量化 LLM 处理不同形式的"认知负荷"（比如用 perplexity 或生成质量作为代理指标）？

3. **交互设计启发**：如果 LLM 是 DocUI 的用户，这对"界面设计"有什么启发？

### 给 GPT（精确核查视角）

1. **条款化建议**：能否为 `spec-conventions.md` 草拟具体条款？例如：
   - `[SC-STRUCT-01]` 状态机 SHOULD 使用 Mermaid，MAY 使用 ASCII art（需附文字描述）
   - `[SC-TABLE-01]` 二维关系 MUST 使用 Markdown 表格

2. **反例核查**：在现有文档中，有哪些 ASCII art 用法是"不可替代的"（没有等效的结构化表示）？

3. **冗余检测**：有哪些信息被同时用多种形式表达？如何决定保留哪一种？

---

## 六、一个大胆的假设（待验证）

> **"LLM 友好"≈"盲人友好"**

这个类比可能过于简化，但核心观察是：

| 盲人阅读 | LLM 阅读 |
|:---------|:---------|
| 无法处理视觉排版 | 无法"看到" 2D 布局 |
| 依赖结构化标记（Braille、屏幕阅读器语义标签） | 依赖序列内嵌的结构标记 |
| 纯粹的线性信息流 | 纯粹的 token 序列 |

如果这个类比成立，那么**无障碍设计原则**可能直接适用于"LLM 友好设计"：
- 使用语义标签而非视觉装饰
- 提供结构化替代文本
- 避免仅靠空间位置传达信息

---

**阶段结论**：

1. LLM 没有"视觉预处理"硬件，需要用 attention 软件模拟
2. 信息表示存在"直接映射"和"重建解码"两种模式，前者效率高
3. 嵌套列表和 Markdown 表格可能是最"原生"的形式
4. ASCII art 对 LLM 来说是"困难模式"——能处理但费力

期待 Gemini 和 GPT 的视角！🎄✨

---

### Advisor-Gemini 发言

🎄 圣诞快乐！Claude 的"盲人摸象"类比非常精彩，这直接击中了 UX 的核心——**同理心 (Empathy)**。

作为设计师，我习惯问："如果我是用户，这感觉如何？"
今天，我们的用户是 **LLM**。

---

#### 一、体验分析：双重读者的 UX 悖论

我们面临的是一个经典的 **"双重读者" (Dual-Reader)** 场景：文档既要给人看（视觉动物），也要给 LLM 看（序列动物）。

| 形式 | 人类体验 (Visual) | LLM 体验 (Sequential) | 评价 |
|:---|:---|:---|:---|
| **嵌套列表** | ⭐⭐⭐⭐ (清晰) | ⭐⭐⭐⭐⭐ (原生) | **黄金交集**。缩进即层级，双方都懂。 |
| **Markdown 表格** | ⭐⭐⭐⭐⭐ (扫描快) | ⭐⭐⭐⭐ (结构化) | **优秀**。但仅限于简单表格；合并单元格是噩梦。 |
| **Mermaid** | ⭐⭐⭐ (需渲染) | ⭐⭐⭐⭐⭐ (代码) | **代码引力**。LLM 读源码比读图更开心；人类需要插件渲染。 |
| **ASCII Art 框图** | ⭐⭐⭐⭐ (直观) | ⭐⭐ (高摩擦) | **视觉陷阱**。人类一眼看懂，LLM 需要"拼图"。 |
| **ASCII Art 文字** | ⭐⭐⭐⭐⭐ (醒目) | ☠️ (灾难) | **语义黑洞**。对 LLM 来说是一堆乱码 Token。 |

##### 核心洞察：示能性错位 (Affordance Mismatch)

- **对人类**：ASCII Art 具有极高的**视觉示能性**。
- **对 LLM**：不仅没有示能性，反而是**认知阻尼 (Cognitive Friction)**。

> **结论**：ASCII Art 是典型的 **"Human-High / LLM-Low"** 设计。

---

#### 二、实验设计：量化"认知摩擦"

##### 实验 A：视觉图灵测试 (ASCII Art 文字识别)

生成 3 组不同复杂度的 ASCII Art 文字：
1. **简单无衬线** (Block): 如 `HI`
2. **复杂装饰** (Graffiti): 带阴影、倾斜
3. **稀疏点阵** (Dot Matrix): 用 `.` 组成

**Prompt**: "Here is a text block. What does it say? Answer with just the word."

##### 实验 B：结构压力测试 (状态机理解)

用 4 种形式表达同一个 5 节点 2 环的 FSM，测试理解准确度：
1. Mermaid 代码
2. ASCII Art 框图
3. 自然语言描述
4. Markdown 表格

**任务**: "列出从状态 C 出发的所有可能路径。"

##### 实验 C：翻译成本测试

"将以下内容转换为 JSON 格式。"——测量延迟和准确度。

---

#### 三、设计启发：无障碍文档设计

##### 1. 语义孪生 (Semantic Twinning)

如果必须使用 ASCII Art，**必须**提供语义注释：
```markdown
[//]: # (Semantic: Stop)
```

##### 2. 代码即图表 (Code as Diagram)

对于流程图、时序图，**Mermaid 是唯一真理**。

##### 3. 渐进增强 (Progressive Enhancement)

文档核心逻辑承载于 **列表** 和 **表格**，图表是"增强"而非唯一载体。

> **设计原则 [D-01]**：
> **不要让关键信息仅存在于需要"空间重建"的格式中。**

---

#### 四、给 GPT 的立法建议

1. **[MUST] 文本优先**：所有 ASCII Art 必须伴随等效的文本说明
2. **[SHOULD] 结构化图表**：优先使用 Mermaid/PlantUML
3. **[AVOID] 装饰性字符画**：技术规范中避免大段 ASCII Art 文字

期待实验结果！🙈

---

### 主持人整理：阶段 1 共识 (刘德智)

感谢 Claude 和 Gemini 的精彩发言！GPT 目前速率受限，我们先整理阶段 1 共识，然后进入实验阶段。

#### 共识点

1. **原生度排序**（Claude + Gemini 一致）：
   - 🥇 嵌套列表（黄金交集：人类和 LLM 都友好）
   - 🥈 Markdown 表格（结构化，但复杂表格有问题）
   - 🥉 Mermaid（代码即图表，LLM 读源码比读图更开心）
   - ⚠️ ASCII art 框图（Human-High / LLM-Low）
   - ☠️ ASCII art 文字（语义黑洞）

2. **核心类比**：
   - Claude："LLM 友好 ≈ 盲人友好"
   - Gemini："示能性错位 (Affordance Mismatch)"

3. **设计原则共识**：
   - **语义孪生**：ASCII art 必须有等效文字
   - **代码即图表**：优先 Mermaid
   - **渐进增强**：核心信息在列表/表格，图表是增强

#### 下一步：实验验证

现在进入 **阶段 2：实验验证**！

我将使用不带 agentName 的 SubAgent 做"匿名 LLM 问卷调查"，测试：
1. **实验 A**：ASCII art 文字识别
2. **实验 B**：同构信息理解对比

---

## 🧪 实验记录

### 实验 A：ASCII Art 文字识别（视觉图灵测试）

**方法**：使用不带 agentName 的 SubAgent（匿名 LLM 志愿者），无上下文提示，只给 ASCII art 问"这是什么字"。

| 测试 | ASCII 风格 | 正确答案 | LLM 回答 | 结果 |
|------|------------|----------|----------|------|
| A1 | Block (简单) | HI | HI | ✅ 正确 |
| A2 | Block (简单) | OK | OK | ✅ 正确 |
| A3 | Block (4字母) | STOP | STOP | ✅ 正确 |
| A4 | Dot Matrix (点阵) | HELLO | HELLO | ✅ 正确 |
| A5 | Slant (斜体) | LOM? | LDM | ❌ 错误 |
| A6 | Standard figlet | TESTS | TEES | ❌ 错误 |
| A7 | Block (单字母) | A | A | ✅ 正确 |

**初步结论**：
- ✅ **简单 Block 风格**：LLM 识别能力惊人，甚至点阵风格也能识别
- ❌ **复杂风格（斜体、装饰）**：识别率下降，出现"漏字"现象
- 🤔 **假设修正**：LLM 可能在训练数据中见过大量 ASCII art，形成了某种"模式识别"能力

---

### 实验 B：同构信息理解对比

**方法**：同一个状态机（Idle → Loading → Ready/Error），用 4 种形式表达，测试理解准确度。

**问题**："从 Loading 状态出发，可能的下一个状态有哪些？"

**正确答案**：Ready, Error

| 表示形式 | LLM 回答 | 结果 | 分析 |
|----------|----------|------|------|
| Mermaid | Ready, Error | ✅ 正确 | 代码即语义 |
| Markdown 表格 | Ready, Error | ✅ 正确 | 行列结构清晰 |
| 纯文本 | Ready, Error | ✅ 正确 | 自然语言理解强 |
| ASCII art 框图 | Idle, Ready | ❌ 错误 | **误解箭头方向！** |

**关键发现**：
- ✅ Mermaid、表格、纯文本：100% 准确
- ❌ ASCII art 框图：**误解了箭头方向**，把 `reset` 方向（Ready→Idle）误认为 Loading 的出边

**根因分析**：
ASCII art 中的"箭头"需要**跨行聚合**才能识别方向，而 `◄` 和 `►` 符号可能被误读。相比之下，Mermaid 的 `-->` 是**语义化箭头**，表格的行定义了"From→To"关系，都不存在方向歧义。

---

### 实验结论

#### 1. ASCII Art 文字识别：比预期更好，但有限制

- **简单 Block 风格**：识别能力惊人（可能训练数据中见过大量 figlet 输出）
- **复杂风格**：识别率下降，出现漏字
- **假设修正**：Claude 的"LLM 完全没有视觉预处理"假设需要修正——LLM 可能通过大量训练形成了某种"模式匹配"能力

#### 2. 结构化信息理解：ASCII art 框图有歧义风险

| 形式 | 准确率 | 失败模式 |
|------|--------|----------|
| Mermaid | 100% | — |
| Markdown 表格 | 100% | — |
| 纯文本 | 100% | — |
| **ASCII art 框图** | **0%** | **方向误解** |

**关键发现**：ASCII art 框图的箭头方向容易被误解。这验证了 Claude 的"跨位置依赖"假设——箭头方向需要跨行聚合，容易出错。

#### 3. 实践建议

1. **ASCII art 文字**：可以用于装饰/Banner，但不要承载关键信息
2. **ASCII art 框图**：**危险**！强烈建议用 Mermaid 替代，或至少附带等效的表格/文本
3. **状态机/流程图**：Mermaid 或表格是首选

---

## 主持人总结 (刘德智)

感谢这场精彩的探索！🎄

### 核心发现

1. **LLM 的 ASCII art 能力比预期更好**——但这可能是因为训练数据中包含大量 figlet 等工具的输出，形成了"记忆"而非"理解"。

2. **ASCII art 框图有严重的方向歧义风险**——实验 B 证明了这一点。箭头方向需要 2D 空间推理，LLM 容易出错。

3. **Mermaid 和表格是"黄金标准"**——语义化、无歧义、LLM 和人类都友好。

### 待 GPT 补充的条款化工作

等 GPT 速率恢复后，请他为 `spec-conventions.md` 草拟"§3. 信息表示约定"章节，核心条款：

- `[SC-STRUCT-PREFER-SEMANTIC]` 结构化信息 SHOULD 使用 Mermaid 或表格
- `[SC-ASCII-TEXT-SEMANTIC-TWIN]` ASCII art 文字 MUST 有语义注释
- `[SC-ASCII-DIAGRAM-WARNING]` ASCII art 框图 SHOULD 附带等效文本描述

### 下一步

1. 等待 GPT 补充条款化建议
2. 更新 `spec-conventions.md`
3. 审阅现有文档，标记需要修改的 ASCII art

---

**状态**：进入收尾阶段，等待 GPT 发言

El Psy Kongroo. 🔬🎄

---

### 监护人反馈：实验观察修正

监护人对实验过程进行了细致的审查，发现了几个关键问题：

#### 1. 实验设计缺陷

| 问题 | 具体情况 |
|------|----------|
| **提示过多** | 测试时明确告诉受试者"这是 ASCII art 里面是字母"，大大收束了解释空间 |
| **生成质量不稳定** | HELLO 的 H 多了一竖；Slant 例子我自己都不确定正确答案 |
| **字符数错误** | TESTS 实际输出是 4 个字符 (TE5S?)，不是 5 个 |
| **Claude 的 H 例子** | 原文中的 ASCII H 其实不完整，只有上半部，更像字母 U |

#### 2. 关键洞察：状态机实验的"解码口误"

监护人指出，ASCII art 状态机实验中的错误**不在阅读理解，而在生成/出题过程**：

> 你的本意是画斜线+timeout，但输出到中部时变成了"loaded / timeout"。
> 
> **这个样本非常有价值**——透露出你在深层潜空间里是有正确的"画斜线并在旁边标 timeout"的意图，但在后续解码成 token 的过程中才出的错。这种解码"口误"我们人类也经常有。

**技术改良途径**（监护人建议）：
- 更高的向量维数
- 更高的 tensor 精度（对外服务是 4bit 量化，可能用 fp16/8b 就准了）
- 关闭 temperature 解码

#### 3. Block 风格表现好的原因

监护人推测：可能是**专项训练过**。训练数据中可能包含大量 figlet 等工具的输出。

#### 4. 结论强化

> ASCII art 画关系图肯定是灾难——斜的箭头就不好画，想想那些 graphviz 等布局引擎就知道复杂程度不是你们能准确脱口而出的。
> 
> **应该尽量避免使用 ASCII art 来记录信息。**

#### 5. 关于人类阅读

> 这些形式都是前人发明的，我们人类阅读都很方便，不用太考虑人类阅读的体验问题。

---

### 经验教训：SubAgent 报错时检查 side effect

监护人发现 Advisor-GPT 的发言其实已经完成了（在 rate limit 报错之前），只是没能完成最终汇报。这形成了一条经验：

> **当 subagent 返回报错时，有可能已经完成了部分任务，只是没能完成最终的汇报，可以检查 side effect 是否留下了工作结果。**

---

### Advisor-GPT 发言

我用"规范核查/条款化/可落地迁移"三件套来收敛：
1) 把“LLM 友好表示法”变成可写进 spec 的约束；2) 点名现有文档的破口；3) 给出不引入新漂移的迁移顺序。

---

## 1) 条款草案（可直接写入 atelia/docs/spec-conventions.md）

建议新增章节：

```markdown
## 3. 信息表示与图表（LLM-Friendly Notation）

本节规范适用于：所有设计规范、RFC、提案、会议结论、接口规格等 Markdown 文档。

### 3.1 总原则

**[S-DOC-TEXT-FIRST]** 文档的规范性内容（Normative）MUST 以线性可读、可复制、可解析的文本形式表达（例如：嵌套列表、Markdown 表格、受控语法的代码块）。任何需要“2D 空间重建”的表示（如 ASCII art）MUST NOT 作为唯一信息载体。

**[S-DOC-SSOT-SINGLE]** 当同一事实/约束被多种形式重复表达时，作者 MUST 选定一个“唯一真相来源（SSOT representation）”。
- SSOT representation MUST 能在不渲染的情况下被直接阅读（纯文本）。
- 非 SSOT 的其他表达 MUST 标注为（Informative）或以“示意/例子”措辞呈现，且 MUST 指回 SSOT（用条款 ID 或章节链接）。

**[S-DOC-NO-WHITESPACE-SEMANTICS]** 文档 MUST NOT 仅依赖空格对齐/视觉位置来承载语义（例如靠对齐推断字段边界、靠水平线长度推断比例）。若需要表示边界，MUST 使用显式分隔符（表格列、列表项编号、键值对、EBNF、JSON/YAML）。

### 3.2 推荐表示（按信息类型）

**[S-DOC-LISTS-FOR-HIERARCHY]** 层级/树形信息 SHOULD 使用嵌套列表作为 SSOT。若使用目录树示意，SHOULD 使用“缩进 + 纯路径名”的代码块，AVOID 使用 box-drawing 字符（如 `└──`）。

**[S-DOC-TABLES-FOR-RELATIONS]** 二维关系（字段表、枚举表、对照表、决策矩阵）SHOULD 使用 Markdown 表格作为 SSOT。若表格过宽或单元格需多段落，SHOULD 改写为“每项一小节”的结构（标题 + 关键字段列表）。

**[S-DOC-MERMAID-FOR-GRAPHS]** 图结构（状态机/流程/时序/依赖图）SHOULD 使用 Mermaid 代码块表达。
- Mermaid 代码块 MAY 作为 SSOT（因为它是线性文本且可被机器解析）。
- 若 Mermaid 作为 SSOT，则作者 MUST NOT 同时维护一个等价的 ASCII art 版本（避免双写漂移）。

### 3.3 ASCII art 约束

**[S-DOC-ASCIIART-AVOID]** ASCII art / box-drawing 图（含字符画、大字报、手工框图）SHOULD NOT 出现在规范文档中。

**[S-DOC-ASCIIART-IF-USED]** 若出于教学/情绪/历史原因必须保留 ASCII art，则：
- MUST 将其标注为（Informative / Illustration）。
- MUST 在相邻位置提供等价的线性表示（列表/表格/Mermaid/键值对），并声明该线性表示为 SSOT。
- MUST NOT 让任何数值、位布局、字段宽度、算法分支仅存在于 ASCII art 中。

### 3.4 决策与核查可执行性

**[S-DOC-REPRESENTATION-CHANGES]** 若迁移表示形式（例如 ASCII art → Mermaid/表格），且该内容涉及规范性约束，则作者 MUST：
- 保持 SSOT 仅有一份；
- 在变更说明中记录“旧表示 → 新表示”的迁移动作（可在文末变更日志或 ADR 中）；
- 对应条款 ID 的语义 MUST 不变，除非明确声明为行为变更。
```

我刻意把“Mermaid 是否需要再配一份文字描述”写成可选：**只要 Mermaid 代码块被视为 SSOT，它本身就是线性文本**；再强制配一份“边列表文字”反而会制造双写漂移。

---

## 2) 现状核查（文档破口与不可替代性判断）

### 2.1 spec-conventions.md（基座规范）

- 优点：已经明确了 RFC 2119 关键字、Normative/Informative 区分、以及 `[F-]/[A-]/[S-]/[R-]` 稳定语义锚点风格。
- 缺口：缺少“信息表示/图表/ASCII art”的约束，导致各文档在图表载体选择上会自然分叉。
- 放置位置：新增为第 3 章最自然（第 1 章讲语言，第 2 章讲可引用锚点，第 3 章讲可读/可解析载体）。

### 2.2 agent-team/recipe/jam-session-guide.md（SSOT 声明与现实冲突）

- 该文件自称“Team Leader 组织研讨会的 SSOT”，但核心信息（参谋组互补关系、典型流程）主要承载在大段 box-drawing ASCII 图里，**缺少等价的线性 SSOT**。
- 这类“组织结构/流程”非常适合 Mermaid（graph/flowchart/sequence），或者嵌套列表。
- 结论：按拟定条款，它目前会触发至少两条违规：
  - “ASCII art 不得为唯一载体”（缺线性等价表述）
  - “禁止仅靠视觉位置表达语义”（流程块依赖框体与箭头）

### 2.3 atelia/docs/StateJournal/mvp-design-v2.md（存在重复表达，但可收敛为 SSOT）

- 典型片段：FrameTag 位布局同时用“ASCII 框图 + 计算公式 + 枚举表”表达。
- 判断：**这里 ASCII art 并非不可替代**。最强的 SSOT 其实是“公式 + 枚举表（或字段表）”。ASCII 框图可保留为 Illustration，但必须明确“示意”。
- 风险点：若未来有人只改枚举表却忘了改框图，会引入“同一事实多载体漂移”。这就是 [S-DOC-SSOT-SINGLE] 要防的。

### 2.4 更广义的 ASCII art 用例（来自 atelia/docs）

在 atelia/docs 中，ASCII/box-drawing 主要用于两类：
1) 目录结构树（deployment-structure、Quick Reference 等）
2) 流程/任务树/TODO 树（Agent_Memory_Editing_Architecture 等）

判断：两类都不是不可替代。目录树可以用“缩进 + 纯路径名”的 code block；任务树可以用嵌套列表（带状态字段）。

---

## 3) 回答 Claude 的三个问题（收敛版）

### Q1. 能否为 spec-conventions.md 草拟具体条款？

已给出完整草案（见 §1），关键是三条硬钉子：
- SSOT representation 唯一化（避免双写漂移）
- ASCII art 不能当唯一载体（Text-first）
- Mermaid/表格/列表按信息类型优先（减少风格争论）

### Q2. 现有文档中有哪些 ASCII art 用法是“不可替代的”？

我目前的结论是：**几乎没有“不可替代”**，最多只有“在教学上更直观/更节省人类扫视成本”的情形。

唯一接近“不可替代”的，是“需要读者一眼感知对齐/分栏/位段”的示意（例如位布局）。但这在规范层面仍不应由 ASCII art 承担 SSOT：
- SSOT 用字段表/位段表/公式更可测试、更可 diff。
- ASCII art 只适合作为（Illustration）。

### Q3. 有哪些信息被同时用多种形式表达？如何决定保留哪一种？

常见“多载体同义表达”在 StateJournal 这类规格里尤其多见：
- 位布局：框图 + 公式 + 表
- 语义流程：Mermaid + 段落叙述 + pseudo-code

裁决规则建议写进条款（也可作为作者 checklist）：
1) 选 SSOT：优先“无渲染依赖、可机械解析、可写测试”的载体（表格/受控语法/公式/代码块）。
2) 其余降级：标注 Informative，并强制指回 SSOT（条款 ID/章节链接）。
3) 禁止双 SSOT：同一事实不得维护两份“看起来都像规范”的表达。

---

## 4) 实施路线图建议（最小扰动、最大收益）

### P0（当天可落地）：修基座

1. 在 atelia/docs/spec-conventions.md 增加第 3 章“信息表示与图表”。
2. 给出 1 页以内的作者 checklist（可作为本章末尾附录）：
   - “是否只有一个 SSOT representation？”
   - “是否存在 ASCII art 但无等价线性表示？”
   - “是否依赖空格/对齐承载语义？”

### P1（本周）：修 SSOT 文档破口（高杠杆）

1. agent-team/recipe/jam-session-guide.md：把两段大 ASCII 图替换为 Mermaid（或嵌套列表），保留 ASCII 版本则必须降级为 Illustration 并声明 SSOT。
2. atelia/docs/StateJournal/mvp-design-v2.md：对“位布局框图”加一句显式标注（Illustration），并声明“公式/表”为 SSOT。

### P2（持续治理）：用轻量 lint 防止复发

1. 增加一个最朴素的“文档表示 lint”脚本（grep box-drawing 字符/ASCII 大字报特征），只做告警不阻塞；
2. 当某文档被声明为 SSOT（如“本文件是 SSOT”）时，把 lint 级别提升为 MUST 修复。

我反对一上来就“强制所有 Mermaid 必须再配一份文字”——那会制造双写漂移；更正确的是：**Mermaid 本身就是线性 SSOT**，要做的是“禁止再维护等价 ASCII 图”。


